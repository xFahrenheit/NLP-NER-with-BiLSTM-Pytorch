{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T05:47:07.852274Z",
     "iopub.status.busy": "2023-03-26T05:47:07.851899Z",
     "iopub.status.idle": "2023-03-26T05:47:07.858202Z",
     "shell.execute_reply": "2023-03-26T05:47:07.856983Z",
     "shell.execute_reply.started": "2023-03-26T05:47:07.852239Z"
    },
    "id": "OyBE8i-Cb-3_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T05:00:44.487528Z",
     "iopub.status.busy": "2023-03-26T05:00:44.487048Z",
     "iopub.status.idle": "2023-03-26T05:00:45.181374Z",
     "shell.execute_reply": "2023-03-26T05:00:45.180316Z",
     "shell.execute_reply.started": "2023-03-26T05:00:44.487486Z"
    },
    "id": "cb3p73ZfiyDG"
   },
   "outputs": [],
   "source": [
    "# read the text file into a list of strings\n",
    "with open('/data/train', 'r') as f:\n",
    "    data = f.read().splitlines()\n",
    "\n",
    "# split each string into three columns and store in a list\n",
    "rows = []\n",
    "for line in data:\n",
    "    cols = line.split()\n",
    "    if len(cols) == 3:\n",
    "        rows.append(cols)\n",
    "\n",
    "# create a pandas dataframe from the list of rows\n",
    "df = pd.DataFrame(rows, columns = [\"index\", \"token\", \"tag\"])\n",
    "df['index'] = df['index'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2023-03-26T05:47:17.241882Z",
     "iopub.status.busy": "2023-03-26T05:47:17.241479Z",
     "iopub.status.idle": "2023-03-26T05:47:17.255086Z",
     "shell.execute_reply": "2023-03-26T05:47:17.253901Z",
     "shell.execute_reply.started": "2023-03-26T05:47:17.241845Z"
    },
    "id": "rN69dNcni5cf",
    "outputId": "cdc3c75c-29f6-449e-858e-0bbd103a716b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EU</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>German</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204562</th>\n",
       "      <td>1</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204563</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204564</th>\n",
       "      <td>3</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204565</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204566</th>\n",
       "      <td>1</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204567 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index       token     tag\n",
       "0           1          EU   B-ORG\n",
       "1           2     rejects       O\n",
       "2           3      German  B-MISC\n",
       "3           4        call       O\n",
       "4           5          to       O\n",
       "...       ...         ...     ...\n",
       "204562      1     Swansea   B-ORG\n",
       "204563      2           1       O\n",
       "204564      3     Lincoln   B-ORG\n",
       "204565      4           2       O\n",
       "204566      1  -DOCSTART-       O\n",
       "\n",
       "[204567 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T05:47:20.464963Z",
     "iopub.status.busy": "2023-03-26T05:47:20.464275Z",
     "iopub.status.idle": "2023-03-26T05:47:20.519391Z",
     "shell.execute_reply": "2023-03-26T05:47:20.518385Z",
     "shell.execute_reply.started": "2023-03-26T05:47:20.464923Z"
    },
    "id": "VGYwEWxHRhug"
   },
   "outputs": [],
   "source": [
    "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "idx = 2  # start indexing from 2\n",
    "\n",
    "for word in df['token']:\n",
    "    if word not in word2idx:\n",
    "        word2idx[word] = idx\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-26T05:47:32.757544Z",
     "iopub.status.busy": "2023-03-26T05:47:32.756858Z",
     "iopub.status.idle": "2023-03-26T05:47:44.302625Z",
     "shell.execute_reply": "2023-03-26T05:47:44.301515Z",
     "shell.execute_reply.started": "2023-03-26T05:47:32.757507Z"
    },
    "id": "rIIXB4-KVZaF",
    "outputId": "339f92c3-0f13-413b-fc7a-e14082bdf4ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Sentences Shape: torch.Size([14987, 113])\n",
      "Encoded NER Tags Shape: torch.Size([14987, 113])\n"
     ]
    }
   ],
   "source": [
    "ner2idx = {'O': 0, 'B-MISC':1, 'I-MISC':2, 'I-PER':3, 'B-LOC':4, 'I-ORG':5, 'B-PER':6, 'I-LOC':7, 'B-ORG': 8}\n",
    "\n",
    "# initialize lists to store the encoded sentences and NER tags\n",
    "encoded_sentences = []\n",
    "encoded_ner_tags = []\n",
    "sentence = []\n",
    "ner_tags = []\n",
    "\n",
    "\n",
    "# encode the sentences and NER tags into numerical representations\n",
    "for i, row in df.iterrows():\n",
    "    if row['index'] == 1:  # start of a new sentence\n",
    "        if i > 0:\n",
    "            # append the encoded sentence and NER tags to the corresponding lists\n",
    "            encoded_sentences.append(sentence)\n",
    "            encoded_ner_tags.append(ner_tags)\n",
    "        # re-initialize the sentence and NER tags\n",
    "        sentence = []\n",
    "        ner_tags = []\n",
    "    # encode the current word and NER tag\n",
    "    sentence.append(word2idx.get(row['token'], word2idx['<UNK>']))\n",
    "    ner_tags.append(ner2idx[row['tag']])\n",
    "\n",
    "# append the last encoded sentence and NER tags to the corresponding lists\n",
    "encoded_sentences.append(sentence)\n",
    "encoded_ner_tags.append(ner_tags)\n",
    "\n",
    "# pad the encoded sentences and NER tags to the maximum length\n",
    "max_sentence_length = max([len(sentence) for sentence in encoded_sentences])\n",
    "\n",
    "# convert the encoded sentences and NER tags to PyTorch tensors\n",
    "x = [torch.LongTensor(sent) for sent in encoded_sentences]\n",
    "y = [torch.LongTensor(tags) for tags in encoded_ner_tags]\n",
    "\n",
    "# pad the sequences to have the same length using PyTorch's pad_sequence function\n",
    "max_len = max_sentence_length  # or any other desired length\n",
    "x = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=0)\n",
    "y = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=-1)\n",
    "\n",
    "# print the shape of the tensors\n",
    "print('Encoded Sentences Shape:', x.shape)\n",
    "print('Encoded NER Tags Shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFS6MS5bV50I"
   },
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T05:47:44.925725Z",
     "iopub.status.busy": "2023-03-26T05:47:44.925053Z",
     "iopub.status.idle": "2023-03-26T05:47:44.933981Z",
     "shell.execute_reply": "2023-03-26T05:47:44.932693Z",
     "shell.execute_reply.started": "2023-03-26T05:47:44.925686Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model architecture\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, num_layers, dropout):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0) #.from_pretrained\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim * 2, 128)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.activation = nn.ELU()\n",
    "        self.classifier = nn.Linear(128, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_out = self.linear(lstm_out)\n",
    "        lstm_out = self.activation(lstm_out)\n",
    "        lstm_out = self.classifier(lstm_out)\n",
    "        \n",
    "        return lstm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T05:48:40.192917Z",
     "iopub.status.busy": "2023-03-26T05:48:40.192039Z",
     "iopub.status.idle": "2023-03-26T05:48:40.199226Z",
     "shell.execute_reply": "2023-03-26T05:48:40.197800Z",
     "shell.execute_reply.started": "2023-03-26T05:48:40.192873Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the hyperparameters\n",
    "num_epochs = 120\n",
    "batch_size = 8\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "output_size = len(ner2idx)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "num_layers = 1\n",
    "dropout = 0.33\n",
    "learning_rate = 0.5\n",
    "weight = [0.7 , 1, 1, 1.5, 1, 1, 1.5, 1, 1.2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "execution": {
     "iopub.execute_input": "2023-03-26T05:48:43.241651Z",
     "iopub.status.busy": "2023-03-26T05:48:43.240699Z",
     "iopub.status.idle": "2023-03-26T06:18:13.074778Z",
     "shell.execute_reply": "2023-03-26T06:18:13.073756Z",
     "shell.execute_reply.started": "2023-03-26T05:48:43.241593Z"
    },
    "id": "tNX9sHHkAiMm",
    "outputId": "bdc8a341-7d6d-470d-d37a-4bac10915fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Loss: 0.7162939658668787\n",
      "Epoch: 2\n",
      "Loss: 0.3788956966501608\n",
      "Epoch: 3\n",
      "Loss: 0.24828953139648924\n",
      "Epoch: 4\n",
      "Loss: 0.1837484407208347\n",
      "Epoch: 5\n",
      "Loss: 0.14175209745817163\n",
      "Epoch: 6\n",
      "Loss: 0.11480066830825593\n",
      "Epoch: 7\n",
      "Loss: 0.10024724021532126\n",
      "Epoch: 8\n",
      "Loss: 0.09020604242494537\n",
      "Epoch: 9\n",
      "Loss: 0.08094813601388308\n",
      "Epoch: 10\n",
      "Loss: 0.0752748068520918\n",
      "Epoch: 11\n",
      "Loss: 0.06962458150826248\n",
      "Epoch: 12\n",
      "Loss: 0.06404324987229346\n",
      "Epoch: 13\n",
      "Loss: 0.06288156728777573\n",
      "Epoch: 14\n",
      "Loss: 0.06140028297850251\n",
      "Epoch: 15\n",
      "Loss: 0.059183932386798664\n",
      "Epoch: 16\n",
      "Loss: 0.049913060853970494\n",
      "Epoch: 17\n",
      "Loss: 0.048876101991341105\n",
      "Epoch: 18\n",
      "Loss: 0.043591474900831415\n",
      "Epoch: 19\n",
      "Loss: 0.04079056744365392\n",
      "Epoch: 20\n",
      "Loss: 0.03821214825235099\n",
      "Epoch: 21\n",
      "Loss: 0.032324126045963804\n",
      "Epoch: 22\n",
      "Loss: 0.029830537009650125\n",
      "Epoch: 23\n",
      "Loss: 0.023686499797772875\n",
      "Epoch: 24\n",
      "Loss: 0.025547799429054958\n",
      "Epoch: 25\n",
      "Loss: 0.020433832301120575\n",
      "Epoch: 26\n",
      "Loss: 0.02220685251581328\n",
      "Epoch: 27\n",
      "Loss: 0.021666032454547554\n",
      "Epoch: 28\n",
      "Loss: 0.017791139210096545\n",
      "Epoch: 29\n",
      "Loss: 0.01795072878849863\n",
      "Epoch: 30\n",
      "Loss: 0.01550281530277603\n",
      "Epoch: 31\n",
      "Loss: 0.02034304837161124\n",
      "Epoch: 32\n",
      "Loss: 0.021997330153080762\n",
      "Epoch: 33\n",
      "Loss: 0.017717018814670037\n",
      "Epoch: 34\n",
      "Loss: 0.013400018417577321\n",
      "Epoch: 35\n",
      "Loss: 0.015111056644282141\n",
      "Epoch: 36\n",
      "Loss: 0.01600630252605823\n",
      "Epoch: 37\n",
      "Loss: 0.017272850189093875\n",
      "Epoch: 38\n",
      "Loss: 0.019781325990291664\n",
      "Epoch: 39\n",
      "Loss: 0.01341669877535684\n",
      "Epoch: 40\n",
      "Loss: 0.011732557379152629\n",
      "Epoch: 41\n",
      "Loss: 0.010705585358020082\n",
      "Epoch: 42\n",
      "Loss: 0.014529090980621894\n",
      "Epoch: 43\n",
      "Loss: 0.012170593117728458\n",
      "Epoch: 44\n",
      "Loss: 0.00913607598204981\n",
      "Epoch: 45\n",
      "Loss: 0.010405653425917398\n",
      "Epoch: 46\n",
      "Loss: 0.010322481345359713\n",
      "Epoch: 47\n",
      "Loss: 0.008867957580619205\n",
      "Epoch: 48\n",
      "Loss: 0.00823969911612454\n",
      "Epoch: 49\n",
      "Loss: 0.008550745565242511\n",
      "Epoch: 50\n",
      "Loss: 0.009481763504600381\n",
      "Epoch: 51\n",
      "Loss: 0.007879949325375146\n",
      "Epoch: 52\n",
      "Loss: 0.007005851345172833\n",
      "Epoch: 53\n",
      "Loss: 0.005496731619840177\n",
      "Epoch: 54\n",
      "Loss: 0.00826102351297236\n",
      "Epoch: 55\n",
      "Loss: 0.010079294750752152\n",
      "Epoch: 56\n",
      "Loss: 0.010838397492109911\n",
      "Epoch: 57\n",
      "Loss: 0.005669148870171362\n",
      "Epoch: 58\n",
      "Loss: 0.0047893468488348825\n",
      "Epoch: 59\n",
      "Loss: 0.004025372554069244\n",
      "Epoch: 60\n",
      "Loss: 0.006092432974192134\n",
      "Epoch: 61\n",
      "Loss: 0.00604309703076896\n",
      "Epoch: 62\n",
      "Loss: 0.005492706228300194\n",
      "Epoch: 63\n",
      "Loss: 0.006844153960681643\n",
      "Epoch: 64\n",
      "Loss: 0.0065730794899626485\n",
      "Epoch: 65\n",
      "Loss: 0.005937326845038248\n",
      "Epoch: 66\n",
      "Loss: 0.00561965599387816\n",
      "Epoch: 67\n",
      "Loss: 0.005504437258453027\n",
      "Epoch: 68\n",
      "Loss: 0.00623933726051694\n",
      "Epoch: 69\n",
      "Loss: 0.005791071518012462\n",
      "Epoch: 70\n",
      "Loss: 0.004926405608580062\n",
      "Epoch: 71\n",
      "Loss: 0.003800028120421256\n",
      "Epoch: 72\n",
      "Loss: 0.0046533275754848105\n",
      "Epoch: 73\n",
      "Loss: 0.005160318241628529\n",
      "Epoch: 74\n",
      "Loss: 0.003087714534849666\n",
      "Epoch: 75\n",
      "Loss: 0.005082135030873723\n",
      "Epoch: 76\n",
      "Loss: 0.006322864383619473\n",
      "Epoch: 77\n",
      "Loss: 0.008347987366878277\n",
      "Epoch: 78\n",
      "Loss: 0.0058872809365334506\n",
      "Epoch: 79\n",
      "Loss: 0.0037465437561157505\n",
      "Epoch: 80\n",
      "Loss: 0.0033045915817988564\n",
      "Epoch: 81\n",
      "Loss: 0.002202417623499183\n",
      "Epoch: 82\n",
      "Loss: 0.0030031643639066353\n",
      "Epoch: 83\n",
      "Loss: 0.004422864615044004\n",
      "Epoch: 84\n",
      "Loss: 0.004291093959963162\n",
      "Epoch: 85\n",
      "Loss: 0.0027396653241859442\n",
      "Epoch: 86\n",
      "Loss: 0.00415970206525809\n",
      "Epoch: 87\n",
      "Loss: 0.0028963669642500457\n",
      "Epoch: 88\n",
      "Loss: 0.0018290934229952943\n",
      "Epoch: 89\n",
      "Loss: 0.0019116058429232694\n",
      "Epoch: 90\n",
      "Loss: 0.001991899272489517\n",
      "Epoch: 91\n",
      "Loss: 0.004064063739009757\n",
      "Epoch: 92\n",
      "Loss: 0.004324605772786151\n",
      "Epoch: 93\n",
      "Loss: 0.0028193983457902643\n",
      "Epoch: 94\n",
      "Loss: 0.0033654425668306273\n",
      "Epoch: 95\n",
      "Loss: 0.001947726466412519\n",
      "Epoch: 96\n",
      "Loss: 0.0021665093411658972\n",
      "Epoch: 97\n",
      "Loss: 0.0014845274063821946\n",
      "Epoch: 98\n",
      "Loss: 0.0016432066035637432\n",
      "Epoch: 99\n",
      "Loss: 0.001146211740366283\n",
      "Epoch: 100\n",
      "Loss: 0.001571773408998426\n",
      "Epoch: 101\n",
      "Loss: 0.003499455985498666\n",
      "Epoch: 102\n",
      "Loss: 0.005327107081564506\n",
      "Epoch: 103\n",
      "Loss: 0.0033532019027714354\n",
      "Epoch: 104\n",
      "Loss: 0.0020967758189167646\n",
      "Epoch: 105\n",
      "Loss: 0.0012921749727473832\n",
      "Epoch: 106\n",
      "Loss: 0.0006005431333790239\n",
      "Epoch: 107\n",
      "Loss: 0.00047794114779190557\n",
      "Epoch: 108\n",
      "Loss: 0.0005802608636211249\n",
      "Epoch: 109\n",
      "Loss: 0.0006264153740213826\n",
      "Epoch: 110\n",
      "Loss: 0.0004219772164822298\n",
      "Epoch: 111\n",
      "Loss: 0.0003911655803033642\n",
      "Epoch: 112\n",
      "Loss: 0.0003871753004866442\n",
      "Epoch: 113\n",
      "Loss: 0.00038581085031136146\n",
      "Epoch: 114\n",
      "Loss: 0.00037326494023535143\n",
      "Epoch: 115\n",
      "Loss: 0.0003379876847730353\n",
      "Epoch: 116\n",
      "Loss: 0.0003564096437898593\n",
      "Epoch: 117\n",
      "Loss: 0.0003384754161124787\n",
      "Epoch: 118\n",
      "Loss: 0.0003282854342052879\n",
      "Epoch: 119\n",
      "Loss: 0.00033174227026906526\n",
      "Epoch: 120\n",
      "Loss: 0.00032921536093654974\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model = BiLSTM(vocab_size, embedding_dim, hidden_dim, output_size, num_layers, dropout)\n",
    "\n",
    "# set up the optimizer and loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-1, weight= torch.tensor(weight)).cuda()\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate,\n",
    "                                                total_steps=num_epochs*(x.shape[0]//batch_size + 1),\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# loop through the data for the specified number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch:', epoch+1)\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # shuffle the data for each epoch\n",
    "    indices = torch.randperm(len(x))\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    \n",
    "    # loop through the data in batches\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        y_batch = y[i:i+batch_size]\n",
    "        \n",
    "        # zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run the model on the current batch\n",
    "        outputs = model(x_batch.cuda())\n",
    "\n",
    "        # compute the loss and update the parameters\n",
    "        loss = loss_fn(outputs.view(-1, len(ner2idx)).cuda(), y_batch.view(-1).cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print('Loss:', epoch_loss / num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "execution": {
     "iopub.execute_input": "2023-03-26T06:19:12.714733Z",
     "iopub.status.busy": "2023-03-26T06:19:12.714373Z",
     "iopub.status.idle": "2023-03-26T06:19:12.740982Z",
     "shell.execute_reply": "2023-03-26T06:19:12.739804Z",
     "shell.execute_reply.started": "2023-03-26T06:19:12.714701Z"
    },
    "id": "p7PoViW2hhu8",
    "outputId": "cff875b5-9a95-4dac-e1e9-9e3c1f08bc8d"
   },
   "outputs": [],
   "source": [
    "model_name = 'blstm1.pt'\n",
    "\n",
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsNA4DMG-gDj"
   },
   "source": [
    "## Predictions on Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:19:22.514237Z",
     "iopub.status.busy": "2023-03-26T06:19:22.513858Z",
     "iopub.status.idle": "2023-03-26T06:19:22.782293Z",
     "shell.execute_reply": "2023-03-26T06:19:22.781229Z",
     "shell.execute_reply.started": "2023-03-26T06:19:22.514204Z"
    },
    "id": "8jx8vBoQ-kxi"
   },
   "outputs": [],
   "source": [
    "# read the text file into a list of strings\n",
    "with open('/data/dev', 'r') as f:\n",
    "    data = f.read().splitlines()\n",
    "\n",
    "# split each string into three columns and store in a list\n",
    "rows = []\n",
    "for line in data:\n",
    "    cols = line.split()\n",
    "    if len(cols) == 3:\n",
    "        rows.append(cols)\n",
    "\n",
    "# create a pandas dataframe from the list of rows\n",
    "df_dev = pd.DataFrame(rows, columns = [\"index\", \"token\", \"tag\"])\n",
    "df_dev['index'] = df_dev['index'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-26T06:19:30.864833Z",
     "iopub.status.busy": "2023-03-26T06:19:30.864438Z",
     "iopub.status.idle": "2023-03-26T06:19:43.511493Z",
     "shell.execute_reply": "2023-03-26T06:19:43.510447Z",
     "shell.execute_reply.started": "2023-03-26T06:19:30.864798Z"
    },
    "id": "m3Tz2QiXFx4o",
    "outputId": "f05f46b8-ea5e-4ad7-dad8-98bf89790485"
   },
   "outputs": [],
   "source": [
    "model_2 = BiLSTM(vocab_size, embedding_dim, hidden_dim, output_size, num_layers, dropout)\n",
    "model_2.load_state_dict(torch.load(model_name))\n",
    "model_2.eval()\n",
    "\n",
    "idx2ner = {v: k for k, v in ner2idx.items()}\n",
    "\n",
    "# create a list to store the predicted NER tags for each word\n",
    "predicted_tags = []\n",
    "\n",
    "# initialize the encoded sentence and NER tag lists\n",
    "encoded_sentence = []\n",
    "ner_tags = []\n",
    "\n",
    "# loop through each row in the dataframe\n",
    "for i, row in df_dev.iterrows():\n",
    "    \n",
    "    # check if it is the beginning of a new sentence\n",
    "    if row['index'] == 1:\n",
    "        \n",
    "        # check if this is not the first sentence\n",
    "        if i > 0:\n",
    "            \n",
    "            # encode the previous sentence and predict NER tags\n",
    "            encoded_sentence = torch.LongTensor(encoded_sentence)\n",
    "            with torch.no_grad():\n",
    "                output = model_2(encoded_sentence)\n",
    "                predicted_tag_indices = output.argmax(dim=1)\n",
    "                predicted_tags.extend([idx2ner[idx.item()] for idx in predicted_tag_indices])\n",
    "            \n",
    "        # re-initialize the encoded sentence and NER tag lists\n",
    "        encoded_sentence = []\n",
    "        \n",
    "    # encode the current word\n",
    "    encoded_sentence.append(word2idx.get(row['token'], word2idx['<UNK>']))\n",
    "    \n",
    "# encode the last sentence and predict NER tags\n",
    "encoded_sentence = torch.LongTensor(encoded_sentence)\n",
    "with torch.no_grad():\n",
    "    output = model_2(encoded_sentence)\n",
    "    predicted_tag_indices = output.argmax(dim=1)\n",
    "    predicted_tags.extend([idx2ner[idx.item()] for idx in predicted_tag_indices])\n",
    "    \n",
    "# add the predicted tags to the dataframe\n",
    "df_dev['pred'] = predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2023-03-26T06:19:43.514026Z",
     "iopub.status.busy": "2023-03-26T06:19:43.513599Z",
     "iopub.status.idle": "2023-03-26T06:19:43.527711Z",
     "shell.execute_reply": "2023-03-26T06:19:43.526637Z",
     "shell.execute_reply.started": "2023-03-26T06:19:43.513987Z"
    },
    "id": "9KFCDXq8G7Fl",
    "outputId": "c293e120-35fd-4029-ab9d-995b3ddd91c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CRICKET</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>LEICESTERSHIRE</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TAKE</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>OVER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51573</th>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51574</th>\n",
       "      <td>2</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51575</th>\n",
       "      <td>3</td>\n",
       "      <td>Newsroom</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51576</th>\n",
       "      <td>4</td>\n",
       "      <td>880-2-506363</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51577</th>\n",
       "      <td>1</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51578 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index           token    tag   pred\n",
       "0          1         CRICKET      O      O\n",
       "1          2               -      O      O\n",
       "2          3  LEICESTERSHIRE  B-ORG      O\n",
       "3          4            TAKE      O      O\n",
       "4          5            OVER      O      O\n",
       "...      ...             ...    ...    ...\n",
       "51573      1              --      O      O\n",
       "51574      2           Dhaka  B-ORG  B-ORG\n",
       "51575      3        Newsroom  I-ORG  I-ORG\n",
       "51576      4    880-2-506363      O      O\n",
       "51577      1      -DOCSTART-      O      O\n",
       "\n",
       "[51578 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:20:13.525967Z",
     "iopub.status.busy": "2023-03-26T06:20:13.525574Z",
     "iopub.status.idle": "2023-03-26T06:20:16.456704Z",
     "shell.execute_reply": "2023-03-26T06:20:16.455612Z",
     "shell.execute_reply.started": "2023-03-26T06:20:13.525932Z"
    },
    "id": "FE0C4ZM5B0-F"
   },
   "outputs": [],
   "source": [
    "with open('dev1.out', 'w') as f:\n",
    "    f_to_write = \"\"\n",
    "    first_ex = True\n",
    "    count = 1\n",
    "    for i_row, row in df_dev.iterrows():\n",
    "        if(row['index'] == 1):\n",
    "            if first_ex:\n",
    "                first_ex = False\n",
    "            else:\n",
    "                count = 1\n",
    "                f_to_write += \"\\n\"\n",
    "        f_to_write += str(count) + \" \" + row['token'] + \" \" + row['tag'] + \" \" + row['pred']  + \"\\n\"\n",
    "        count+=1\n",
    "    f.write(f_to_write)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
